wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Starting training for 1,000,000 timesteps...
============================================================
[ActionDebug] Step 0: {'action/0': 2, 'action/1': 0, 'action/2': 1, 'action/3': 1}
Step:      1,000 | Episodes:     34 | Mean Reward (100):    0.12 | Best:    -inf
[ActionDebug] Step 1000: {'action/0': 256, 'action/1': 231, 'action/2': 248, 'action/3': 269}
Step:      2,000 | Episodes:     65 | Mean Reward (100):    0.14 | Best:    -inf
[ActionDebug] Step 2000: {'action/0': 499, 'action/1': 451, 'action/2': 495, 'action/3': 559}
Step:      3,000 | Episodes:     93 | Mean Reward (100):    0.19 | Best:    -inf
[ActionDebug] Step 3000: {'action/0': 760, 'action/1': 681, 'action/2': 733, 'action/3': 830}
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000100 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000100.mp4 (reward: 0.0)
Step:      4,000 | Episodes:    128 | Mean Reward (100):    0.18 | Best:    0.19
[ActionDebug] Step 4000: {'action/0': 1030, 'action/1': 946, 'action/2': 961, 'action/3': 1067}
Step:      5,000 | Episodes:    154 | Mean Reward (100):    0.23 | Best:    0.23
[ActionDebug] Step 5000: {'action/0': 1270, 'action/1': 1211, 'action/2': 1218, 'action/3': 1305}
Step:      6,000 | Episodes:    182 | Mean Reward (100):    0.24 | Best:    0.27
[ActionDebug] Step 6000: {'action/0': 1521, 'action/1': 1448, 'action/2': 1477, 'action/3': 1558}
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000200 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000200.mp4 (reward: 0.0)
Step:      7,000 | Episodes:    217 | Mean Reward (100):    0.24 | Best:    0.27
[ActionDebug] Step 7000: {'action/0': 1761, 'action/1': 1712, 'action/2': 1722, 'action/3': 1809}
Step:      8,000 | Episodes:    247 | Mean Reward (100):    0.23 | Best:    0.27
[ActionDebug] Step 8000: {'action/0': 2026, 'action/1': 1945, 'action/2': 1965, 'action/3': 2068}
Step:      9,000 | Episodes:    271 | Mean Reward (100):    0.22 | Best:    0.27
[ActionDebug] Step 9000: {'action/0': 2278, 'action/1': 2191, 'action/2': 2215, 'action/3': 2320}
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000300 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000300.mp4 (reward: 0.0)
Step:     10,000 | Episodes:    304 | Mean Reward (100):    0.24 | Best:    0.28
Step:     11,000 | Episodes:    332 | Mean Reward (100):    0.27 | Best:    0.29
Step:     12,000 | Episodes:    364 | Mean Reward (100):    0.22 | Best:    0.29
Step:     13,000 | Episodes:    393 | Mean Reward (100):    0.19 | Best:    0.29
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000400 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000400.mp4 (reward: 0.0)
Step:     14,000 | Episodes:    428 | Mean Reward (100):    0.19 | Best:    0.29
Step:     15,000 | Episodes:    461 | Mean Reward (100):    0.19 | Best:    0.29
Step:     16,000 | Episodes:    492 | Mean Reward (100):    0.19 | Best:    0.29
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000500 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000500.mp4 (reward: 0.0)
Step:     17,000 | Episodes:    525 | Mean Reward (100):    0.18 | Best:    0.29
Step:     18,000 | Episodes:    556 | Mean Reward (100):    0.22 | Best:    0.29
Step:     19,000 | Episodes:    583 | Mean Reward (100):    0.23 | Best:    0.29
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000600 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000600.mp4 (reward: 0.0)
[Training] Step 20000: policy_loss=-0.0002, grad_norm=0.4242, entropy=1.3863
Step:     20,000 | Episodes:    618 | Mean Reward (100):    0.19 | Best:    0.29
[Training] Step 20100: policy_loss=-0.0005, grad_norm=0.3505, entropy=1.3863
[Training] Step 20200: policy_loss=0.0002, grad_norm=0.1377, entropy=1.3863
[Training] Step 20300: policy_loss=0.0002, grad_norm=0.3659, entropy=1.3863
[Training] Step 20400: policy_loss=0.0009, grad_norm=0.2616, entropy=1.3863
[Training] Step 20500: policy_loss=-0.0022, grad_norm=0.3410, entropy=1.3862
[Training] Step 20600: policy_loss=0.0003, grad_norm=0.2586, entropy=1.3862
[Training] Step 20700: policy_loss=0.0003, grad_norm=0.3394, entropy=1.3863
[Training] Step 20800: policy_loss=0.0016, grad_norm=0.3446, entropy=1.3863
[Training] Step 20900: policy_loss=0.0001, grad_norm=0.4749, entropy=1.3863
[Training] Step 21000: policy_loss=0.0003, grad_norm=0.2822, entropy=1.3863
Step:     21,000 | Episodes:    650 | Mean Reward (100):    0.19 | Best:    0.29
[Training] Step 21100: policy_loss=0.0005, grad_norm=0.2515, entropy=1.3863
[Training] Step 21200: policy_loss=-0.0017, grad_norm=0.2238, entropy=1.3862
[Training] Step 21300: policy_loss=0.0021, grad_norm=0.3037, entropy=1.3861
[Training] Step 21400: policy_loss=-0.0058, grad_norm=0.3271, entropy=1.3857
[Training] Step 21500: policy_loss=-0.0052, grad_norm=0.3602, entropy=1.3856
[Training] Step 21600: policy_loss=0.0001, grad_norm=0.3193, entropy=1.3856
Traceback (most recent call last):
  File ".\src\main.py", line 511, in <module>
    main()
  File ".\src\main.py", line 507, in main
    train(config, args)
  File ".\src\main.py", line 359, in train
    update_metrics = agent.update()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 403, in update
    # Train dynamics on real data
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 275, in generate_model_rollouts
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\utils.py", line 157, in add_batch
    self._store_at_indices(indices, states, actions, rewards, next_states, dones)
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\utils.py", line 194, in _store_at_indices
    np.clip(states, 0, 255, out=states if states.flags.writeable else None)
  File "<__array_function__ internals>", line 200, in clip
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\fromnumeric.py", line 2180, in clip
    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\_methods.py", line 161, in _clip
    return _clip_dep_invoke_with_casting(
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\_methods.py", line 115, in _clip_dep_invoke_with_casting
    return ufunc(*args, out=out, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File ".\src\main.py", line 511, in <module>
    main()
  File ".\src\main.py", line 507, in main
    train(config, args)
  File ".\src\main.py", line 359, in train
    update_metrics = agent.update()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 403, in update
    # Train dynamics on real data
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 275, in generate_model_rollouts
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\utils.py", line 157, in add_batch
    self._store_at_indices(indices, states, actions, rewards, next_states, dones)
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\utils.py", line 194, in _store_at_indices
    np.clip(states, 0, 255, out=states if states.flags.writeable else None)
  File "<__array_function__ internals>", line 200, in clip
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\fromnumeric.py", line 2180, in clip
    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\_methods.py", line 161, in _clip
    return _clip_dep_invoke_with_casting(
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\numpy\core\_methods.py", line 115, in _clip_dep_invoke_with_casting
    return ufunc(*args, out=out, **kwargs)
KeyboardInterrupt
