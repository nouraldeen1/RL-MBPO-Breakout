wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Starting training for 10,000,000 timesteps...
============================================================
Step:      1,000 | Episodes:     33 | Mean Reward (100):    0.15 | Best:    -inf
Step:      2,000 | Episodes:     65 | Mean Reward (100):    0.18 | Best:    -inf
Step:      3,000 | Episodes:    100 | Mean Reward (100):    0.15 | Best:    0.15
Step:      4,000 | Episodes:    130 | Mean Reward (100):    0.15 | Best:    0.18
Step:      5,000 | Episodes:    155 | Mean Reward (100):    0.20 | Best:    0.22
Step:      6,000 | Episodes:    184 | Mean Reward (100):    0.28 | Best:    0.28
Step:      7,000 | Episodes:    206 | Mean Reward (100):    0.37 | Best:    0.37
Step:      8,000 | Episodes:    241 | Mean Reward (100):    0.35 | Best:    0.39
Step:      9,000 | Episodes:    268 | Mean Reward (100):    0.30 | Best:    0.39
Step:     10,000 | Episodes:    301 | Mean Reward (100):    0.19 | Best:    0.39
Step:     11,000 | Episodes:    336 | Mean Reward (100):    0.18 | Best:    0.39
Step:     12,000 | Episodes:    371 | Mean Reward (100):    0.13 | Best:    0.39
Step:     13,000 | Episodes:    402 | Mean Reward (100):    0.15 | Best:    0.39
Step:     14,000 | Episodes:    427 | Mean Reward (100):    0.23 | Best:    0.39
Step:     15,000 | Episodes:    453 | Mean Reward (100):    0.30 | Best:    0.39
Step:     16,000 | Episodes:    481 | Mean Reward (100):    0.33 | Best:    0.39
Step:     17,000 | Episodes:    511 | Mean Reward (100):    0.29 | Best:    0.39
Step:     18,000 | Episodes:    536 | Mean Reward (100):    0.33 | Best:    0.39
Step:     19,000 | Episodes:    566 | Mean Reward (100):    0.25 | Best:    0.39
Step:     20,000 | Episodes:    590 | Mean Reward (100):    0.30 | Best:    0.39
Step:     21,000 | Episodes:    613 | Mean Reward (100):    0.37 | Best:    0.39

============================================================
Early stopping triggered: No improvement for 400 episodes
Final mean reward: 0.37
Total episodes: 615
Total timesteps: 21,052
Final model saved to checkpoints/final_mbpo.pt
wandb: WARNING `format` argument was not provided, defaulting to `gif`. This parameter will be required in v0.20.0, please specify the format explicitly.
