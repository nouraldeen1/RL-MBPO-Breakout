wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Starting training for 1,000,000 timesteps...
============================================================
[ActionDebug] Step 0: {'action/0': 2, 'action/1': 0, 'action/2': 1, 'action/3': 1}
Step:      1,000 | Episodes:     35 | Mean Reward (100):    0.09 | Best:    -inf
[ActionDebug] Step 1000: {'action/0': 256, 'action/1': 231, 'action/2': 248, 'action/3': 269}
Step:      2,000 | Episodes:     61 | Mean Reward (100):    0.20 | Best:    -inf
[ActionDebug] Step 2000: {'action/0': 499, 'action/1': 451, 'action/2': 495, 'action/3': 559}
Step:      3,000 | Episodes:     91 | Mean Reward (100):    0.21 | Best:    -inf
[ActionDebug] Step 3000: {'action/0': 760, 'action/1': 681, 'action/2': 733, 'action/3': 830}
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000100 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000100.mp4 (reward: 0.0)
Step:      4,000 | Episodes:    126 | Mean Reward (100):    0.22 | Best:    0.24
[ActionDebug] Step 4000: {'action/0': 1030, 'action/1': 946, 'action/2': 961, 'action/3': 1067}
Step:      5,000 | Episodes:    154 | Mean Reward (100):    0.26 | Best:    0.28
[ActionDebug] Step 5000: {'action/0': 1270, 'action/1': 1211, 'action/2': 1218, 'action/3': 1305}
Step:      6,000 | Episodes:    187 | Mean Reward (100):    0.20 | Best:    0.28
[ActionDebug] Step 6000: {'action/0': 1521, 'action/1': 1448, 'action/2': 1477, 'action/3': 1558}
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000201 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000201.mp4 (reward: 0.0)
Step:      7,000 | Episodes:    209 | Mean Reward (100):    0.27 | Best:    0.30
[ActionDebug] Step 7000: {'action/0': 1761, 'action/1': 1712, 'action/2': 1722, 'action/3': 1809}
Step:      8,000 | Episodes:    235 | Mean Reward (100):    0.34 | Best:    0.37
[ActionDebug] Step 8000: {'action/0': 2026, 'action/1': 1945, 'action/2': 1965, 'action/3': 2068}
Step:      9,000 | Episodes:    263 | Mean Reward (100):    0.35 | Best:    0.38
[ActionDebug] Step 9000: {'action/0': 2279, 'action/1': 2191, 'action/2': 2215, 'action/3': 2319}
Step:     10,000 | Episodes:    292 | Mean Reward (100):    0.38 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000300 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000300.mp4 (reward: 0.0)
Step:     11,000 | Episodes:    322 | Mean Reward (100):    0.29 | Best:    0.39
Step:     12,000 | Episodes:    353 | Mean Reward (100):    0.25 | Best:    0.39
Step:     13,000 | Episodes:    371 | Mean Reward (100):    0.33 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000400 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000400.mp4 (reward: 0.0)
Step:     14,000 | Episodes:    405 | Mean Reward (100):    0.30 | Best:    0.39
Step:     15,000 | Episodes:    433 | Mean Reward (100):    0.31 | Best:    0.39
Step:     16,000 | Episodes:    467 | Mean Reward (100):    0.21 | Best:    0.39
Step:     17,000 | Episodes:    491 | Mean Reward (100):    0.23 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000500 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000500.mp4 (reward: 0.0)
Step:     18,000 | Episodes:    527 | Mean Reward (100):    0.24 | Best:    0.39
Step:     19,000 | Episodes:    552 | Mean Reward (100):    0.27 | Best:    0.39
[Training] Step 20000: policy_loss=0.0001, grad_norm=0.4368, entropy=1.3863
Step:     20,000 | Episodes:    584 | Mean Reward (100):    0.23 | Best:    0.39
[Training] Step 20100: policy_loss=-0.0000, grad_norm=0.1818, entropy=1.3863
[Training] Step 20200: policy_loss=-0.0004, grad_norm=0.3116, entropy=1.3863
[Training] Step 20300: policy_loss=-0.0005, grad_norm=0.2039, entropy=1.3863
[Training] Step 20400: policy_loss=-0.0001, grad_norm=0.3018, entropy=1.3863
[Training] Step 20500: policy_loss=-0.0002, grad_norm=0.3829, entropy=1.3863
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000600 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000600.mp4 (reward: 0.0)
[Training] Step 20600: policy_loss=-0.0016, grad_norm=0.2954, entropy=1.3862
[Training] Step 20700: policy_loss=-0.0002, grad_norm=0.3132, entropy=1.3862
[Training] Step 20800: policy_loss=0.0012, grad_norm=0.3035, entropy=1.3862
[Training] Step 20900: policy_loss=-0.0018, grad_norm=0.3758, entropy=1.3862
[Training] Step 21000: policy_loss=-0.0015, grad_norm=0.2156, entropy=1.3862
Step:     21,000 | Episodes:    612 | Mean Reward (100):    0.25 | Best:    0.39
[Training] Step 21100: policy_loss=0.0023, grad_norm=0.4072, entropy=1.3862
[Training] Step 21200: policy_loss=0.0013, grad_norm=0.3293, entropy=1.3862
[Training] Step 21300: policy_loss=0.0011, grad_norm=0.3232, entropy=1.3862
[Training] Step 21400: policy_loss=-0.0000, grad_norm=0.3589, entropy=1.3862
[Training] Step 21500: policy_loss=0.0016, grad_norm=0.2281, entropy=1.3862
[Training] Step 21600: policy_loss=0.0028, grad_norm=0.3278, entropy=1.3862
[Training] Step 21700: policy_loss=0.0005, grad_norm=0.1748, entropy=1.3862
[Training] Step 21800: policy_loss=-0.0037, grad_norm=0.3392, entropy=1.3861
[Training] Step 21900: policy_loss=-0.0022, grad_norm=0.3285, entropy=1.3861
[Training] Step 22000: policy_loss=0.0010, grad_norm=0.3744, entropy=1.3859
Step:     22,000 | Episodes:    644 | Mean Reward (100):    0.22 | Best:    0.39
[Training] Step 22100: policy_loss=-0.0020, grad_norm=0.4224, entropy=1.3858
[Training] Step 22200: policy_loss=0.0012, grad_norm=0.3148, entropy=1.3856
[Training] Step 22300: policy_loss=-0.0055, grad_norm=0.3994, entropy=1.3858
[Training] Step 22400: policy_loss=-0.0076, grad_norm=0.4697, entropy=1.3857
[Training] Step 22500: policy_loss=0.0039, grad_norm=0.4161, entropy=1.3858
[Training] Step 22600: policy_loss=-0.0071, grad_norm=0.3773, entropy=1.3856
[Training] Step 22700: policy_loss=-0.0085, grad_norm=0.4053, entropy=1.3851
[Training] Step 22800: policy_loss=-0.0081, grad_norm=0.6559, entropy=1.3850
[Training] Step 22900: policy_loss=-0.0004, grad_norm=0.4043, entropy=1.3854
[Training] Step 23000: policy_loss=-0.0060, grad_norm=0.3011, entropy=1.3857
Step:     23,000 | Episodes:    670 | Mean Reward (100):    0.25 | Best:    0.39
[Training] Step 23100: policy_loss=-0.0021, grad_norm=0.3471, entropy=1.3857
[Training] Step 23200: policy_loss=-0.0094, grad_norm=0.3916, entropy=1.3851
[Training] Step 23300: policy_loss=-0.0043, grad_norm=0.6157, entropy=1.3841
[Training] Step 23400: policy_loss=-0.0034, grad_norm=0.4876, entropy=1.3828
[Training] Step 23500: policy_loss=-0.0051, grad_norm=0.3895, entropy=1.3832
[Training] Step 23600: policy_loss=-0.0002, grad_norm=0.5947, entropy=1.3828
[Training] Step 23700: policy_loss=-0.0153, grad_norm=0.7223, entropy=1.3800
[Training] Step 23800: policy_loss=-0.0385, grad_norm=0.9747, entropy=1.3752
[Training] Step 23900: policy_loss=0.0113, grad_norm=0.9304, entropy=1.3731
[Training] Step 24000: policy_loss=-0.0213, grad_norm=0.8933, entropy=1.3670
Step:     24,000 | Episodes:    695 | Mean Reward (100):    0.33 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000700 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000700.mp4 (reward: 0.0)
[Training] Step 24100: policy_loss=0.0426, grad_norm=1.2868, entropy=1.3659
[Training] Step 24200: policy_loss=0.0300, grad_norm=1.1262, entropy=1.3705
[Training] Step 24300: policy_loss=-0.0216, grad_norm=0.6810, entropy=1.3705
[Training] Step 24400: policy_loss=-0.0104, grad_norm=1.1450, entropy=1.3637
[Training] Step 24500: policy_loss=-0.0126, grad_norm=1.0580, entropy=1.3656
[Training] Step 24600: policy_loss=0.0467, grad_norm=1.3688, entropy=1.3571
[Training] Step 24700: policy_loss=-0.0131, grad_norm=1.2175, entropy=1.3432
[Training] Step 24800: policy_loss=-0.0364, grad_norm=1.1416, entropy=1.3319
[Training] Step 24900: policy_loss=0.0247, grad_norm=1.6156, entropy=1.3382
[Training] Step 25000: policy_loss=-0.0116, grad_norm=1.1614, entropy=1.3440
Step:     25,000 | Episodes:    726 | Mean Reward (100):    0.34 | Best:    0.39
Step:     26,000 | Episodes:    754 | Mean Reward (100):    0.33 | Best:    0.39
Step:     27,000 | Episodes:    786 | Mean Reward (100):    0.33 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000800 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000800.mp4 (reward: 0.0)
Step:     28,000 | Episodes:    815 | Mean Reward (100):    0.32 | Best:    0.39
Step:     29,000 | Episodes:    846 | Mean Reward (100):    0.26 | Best:    0.39
Step:     30,000 | Episodes:    882 | Mean Reward (100):    0.21 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-000900 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-000900.mp4 (reward: 0.0)
Step:     31,000 | Episodes:    918 | Mean Reward (100):    0.15 | Best:    0.39
Step:     32,000 | Episodes:    944 | Mean Reward (100):    0.16 | Best:    0.39
Step:     33,000 | Episodes:    971 | Mean Reward (100):    0.22 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001000 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001000.mp4 (reward: 0.0)
Step:     34,000 | Episodes:   1007 | Mean Reward (100):    0.22 | Best:    0.39
Step:     35,000 | Episodes:   1041 | Mean Reward (100):    0.19 | Best:    0.39
Step:     36,000 | Episodes:   1072 | Mean Reward (100):    0.20 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001101 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001101.mp4 (reward: 0.0)
Step:     37,000 | Episodes:   1104 | Mean Reward (100):    0.18 | Best:    0.39
Step:     38,000 | Episodes:   1132 | Mean Reward (100):    0.27 | Best:    0.39
Step:     39,000 | Episodes:   1161 | Mean Reward (100):    0.21 | Best:    0.39
Step:     40,000 | Episodes:   1182 | Mean Reward (100):    0.33 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001200 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001200.mp4 (reward: 0.0)
Step:     41,000 | Episodes:   1208 | Mean Reward (100):    0.37 | Best:    0.39
Step:     42,000 | Episodes:   1234 | Mean Reward (100):    0.33 | Best:    0.39
Step:     43,000 | Episodes:   1262 | Mean Reward (100):    0.39 | Best:    0.39
Step:     44,000 | Episodes:   1296 | Mean Reward (100):    0.29 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001300 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001300.mp4 (reward: 0.0)
Step:     45,000 | Episodes:   1328 | Mean Reward (100):    0.27 | Best:    0.39
Step:     46,000 | Episodes:   1359 | Mean Reward (100):    0.21 | Best:    0.39
Step:     47,000 | Episodes:   1385 | Mean Reward (100):    0.24 | Best:    0.39
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001400 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001400.mp4 (reward: 0.0)
Step:     48,000 | Episodes:   1409 | Mean Reward (100):    0.30 | Best:    0.39
Step:     49,000 | Episodes:   1432 | Mean Reward (100):    0.35 | Best:    0.39
Step:     50,000 | Episodes:   1457 | Mean Reward (100):    0.43 | Best:    0.43
Step:     51,000 | Episodes:   1486 | Mean Reward (100):    0.40 | Best:    0.45
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001500 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001500.mp4 (reward: 0.0)
Step:     52,000 | Episodes:   1512 | Mean Reward (100):    0.36 | Best:    0.45
Step:     53,000 | Episodes:   1538 | Mean Reward (100):    0.36 | Best:    0.45
Step:     54,000 | Episodes:   1573 | Mean Reward (100):    0.30 | Best:    0.45
C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\gymnasium\wrappers\rendering.py:283: UserWarning: [33mWARN: Overwriting existing videos at D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\videos\eval-001600 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)[0m
  logger.warn(
[Video] Saved episode video: videos\eval-episode-001600.mp4 (reward: 0.0)
Step:     55,000 | Episodes:   1607 | Mean Reward (100):    0.25 | Best:    0.45
Step:     56,000 | Episodes:   1640 | Mean Reward (100):    0.11 | Best:    0.45
Step:     57,000 | Episodes:   1662 | Mean Reward (100):    0.22 | Best:    0.45
Step:     58,000 | Episodes:   1679 | Mean Reward (100):    0.33 | Best:    0.45
Traceback (most recent call last):
  File ".\src\main.py", line 511, in <module>
    main()
  File ".\src\main.py", line 507, in main
    train(config, args)
  File ".\src\main.py", line 359, in train
    update_metrics = agent.update()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 396, in update
    n_generated = self.generate_model_rollouts()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 258, in generate_model_rollouts
    actions, _, _, _ = self.actor_critic.get_action_and_value(states)
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\models.py", line 791, in get_action_and_value
    entropy = dist.entropy()
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\torch\distributions\categorical.py", line 148, in entropy
    return -p_log_p.sum(-1)
KeyboardInterrupt
Traceback (most recent call last):
  File ".\src\main.py", line 511, in <module>
    main()
  File ".\src\main.py", line 507, in main
    train(config, args)
  File ".\src\main.py", line 359, in train
    update_metrics = agent.update()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 396, in update
    n_generated = self.generate_model_rollouts()
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\agents.py", line 258, in generate_model_rollouts
    actions, _, _, _ = self.actor_critic.get_action_and_value(states)
  File "D:\as3b folder\CCE-C\term 5\rl\RL-last\RL-MBPO-Breakout\src\models.py", line 791, in get_action_and_value
    entropy = dist.entropy()
  File "C:\Users\nourh\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\torch\distributions\categorical.py", line 148, in entropy
    return -p_log_p.sum(-1)
KeyboardInterrupt
