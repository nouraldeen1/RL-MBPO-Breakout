wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Starting training for 10,000,000 timesteps...
============================================================
Step:      1,000 | Episodes:     19 | Mean Reward (100):    0.53 | Best:    -inf
Step:      2,000 | Episodes:     49 | Mean Reward (100):    0.39 | Best:    -inf
Step:      3,000 | Episodes:     83 | Mean Reward (100):    0.29 | Best:    -inf
Step:      4,000 | Episodes:    110 | Mean Reward (100):    0.27 | Best:    0.32
Step:      5,000 | Episodes:    137 | Mean Reward (100):    0.26 | Best:    0.32
Step:      6,000 | Episodes:    168 | Mean Reward (100):    0.26 | Best:    0.32
Step:      7,000 | Episodes:    194 | Mean Reward (100):    0.30 | Best:    0.32
Step:      8,000 | Episodes:    228 | Mean Reward (100):    0.22 | Best:    0.32
Step:      9,000 | Episodes:    261 | Mean Reward (100):    0.21 | Best:    0.32
Step:     10,000 | Episodes:    294 | Mean Reward (100):    0.19 | Best:    0.32
Step:     11,000 | Episodes:    324 | Mean Reward (100):    0.19 | Best:    0.32
Step:     12,000 | Episodes:    356 | Mean Reward (100):    0.18 | Best:    0.32
Step:     13,000 | Episodes:    381 | Mean Reward (100):    0.23 | Best:    0.32
Step:     14,000 | Episodes:    406 | Mean Reward (100):    0.34 | Best:    0.34
Step:     15,000 | Episodes:    430 | Mean Reward (100):    0.38 | Best:    0.38
Step:     16,000 | Episodes:    457 | Mean Reward (100):    0.41 | Best:    0.43
Step:     17,000 | Episodes:    484 | Mean Reward (100):    0.40 | Best:    0.44
Step:     18,000 | Episodes:    511 | Mean Reward (100):    0.35 | Best:    0.44
Step:     19,000 | Episodes:    539 | Mean Reward (100):    0.28 | Best:    0.44
Step:     20,000 | Episodes:    570 | Mean Reward (100):    0.30 | Best:    0.44
Step:     21,000 | Episodes:    600 | Mean Reward (100):    0.26 | Best:    0.44
Step:     22,000 | Episodes:    629 | Mean Reward (100):    0.24 | Best:    0.44
Step:     23,000 | Episodes:    664 | Mean Reward (100):    0.23 | Best:    0.44
Step:     24,000 | Episodes:    690 | Mean Reward (100):    0.25 | Best:    0.44
Step:     25,000 | Episodes:    715 | Mean Reward (100):    0.30 | Best:    0.44
Step:     26,000 | Episodes:    742 | Mean Reward (100):    0.32 | Best:    0.44
Step:     27,000 | Episodes:    770 | Mean Reward (100):    0.36 | Best:    0.44
Step:     28,000 | Episodes:    802 | Mean Reward (100):    0.30 | Best:    0.44
Step:     29,000 | Episodes:    826 | Mean Reward (100):    0.31 | Best:    0.44
Step:     30,000 | Episodes:    854 | Mean Reward (100):    0.27 | Best:    0.44

============================================================
Early stopping triggered: No improvement for 400 episodes
Final mean reward: 0.30
Total episodes: 864
Total timesteps: 30,424
Final model saved to checkpoints/final_mbpo.pt
wandb: WARNING `format` argument was not provided, defaulting to `gif`. This parameter will be required in v0.20.0, please specify the format explicitly.
