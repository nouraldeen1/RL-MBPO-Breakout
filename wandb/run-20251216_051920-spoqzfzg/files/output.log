wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Starting training for 10,000,000 timesteps...
============================================================
Step:      1,000 | Episodes:     23 | Mean Reward (100):    0.43 | Best:    -inf
Step:      2,000 | Episodes:     51 | Mean Reward (100):    0.35 | Best:    -inf
Step:      3,000 | Episodes:     80 | Mean Reward (100):    0.33 | Best:    -inf
Step:      4,000 | Episodes:    105 | Mean Reward (100):    0.34 | Best:    0.34
Step:      5,000 | Episodes:    125 | Mean Reward (100):    0.40 | Best:    0.40
Step:      6,000 | Episodes:    151 | Mean Reward (100):    0.40 | Best:    0.42
Step:      7,000 | Episodes:    183 | Mean Reward (100):    0.41 | Best:    0.42
Step:      8,000 | Episodes:    213 | Mean Reward (100):    0.33 | Best:    0.43
Step:      9,000 | Episodes:    239 | Mean Reward (100):    0.27 | Best:    0.43
Step:     10,000 | Episodes:    268 | Mean Reward (100):    0.24 | Best:    0.43
Step:     11,000 | Episodes:    294 | Mean Reward (100):    0.28 | Best:    0.43
Step:     12,000 | Episodes:    327 | Mean Reward (100):    0.33 | Best:    0.43
Step:     13,000 | Episodes:    355 | Mean Reward (100):    0.31 | Best:    0.43
Step:     14,000 | Episodes:    381 | Mean Reward (100):    0.29 | Best:    0.43
Step:     15,000 | Episodes:    402 | Mean Reward (100):    0.34 | Best:    0.43
Step:     16,000 | Episodes:    427 | Mean Reward (100):    0.42 | Best:    0.44
Step:     17,000 | Episodes:    457 | Mean Reward (100):    0.42 | Best:    0.46
Step:     18,000 | Episodes:    491 | Mean Reward (100):    0.32 | Best:    0.46
Step:     19,000 | Episodes:    519 | Mean Reward (100):    0.25 | Best:    0.46
Step:     20,000 | Episodes:    553 | Mean Reward (100):    0.15 | Best:    0.46
Step:     21,000 | Episodes:    591 | Mean Reward (100):    0.19 | Best:    0.46
Step:     22,000 | Episodes:    624 | Mean Reward (100):    0.14 | Best:    0.46
Step:     23,000 | Episodes:    658 | Mean Reward (100):    0.13 | Best:    0.46
Step:     24,000 | Episodes:    687 | Mean Reward (100):    0.16 | Best:    0.46
Step:     25,000 | Episodes:    709 | Mean Reward (100):    0.26 | Best:    0.46
Step:     26,000 | Episodes:    742 | Mean Reward (100):    0.25 | Best:    0.46
Step:     27,000 | Episodes:    762 | Mean Reward (100):    0.34 | Best:    0.46
Step:     28,000 | Episodes:    792 | Mean Reward (100):    0.33 | Best:    0.46
Step:     29,000 | Episodes:    822 | Mean Reward (100):    0.31 | Best:    0.46

============================================================
Early stopping triggered: No improvement for 400 episodes
Final mean reward: 0.31
Total episodes: 845
Total timesteps: 29,816
Final model saved to checkpoints/final_mbpo.pt
wandb: WARNING `format` argument was not provided, defaulting to `gif`. This parameter will be required in v0.20.0, please specify the format explicitly.
